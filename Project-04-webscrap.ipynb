{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_scrap (job_url):\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=\"/Users/yesplum/desktop/GApro/chromedriver/chromedriver\")\n",
    "    driver.get(job_url)\n",
    "    sleep(5)\n",
    "    html = driver.page_source\n",
    "    sleep(3)\n",
    "    driver.close()\n",
    "    soup = BeautifulSoup(html, 'lxml', from_encoding=\"utf-8\")\n",
    "    \n",
    "    job_title = []\n",
    "    company = []\n",
    "    job_id = []\n",
    "    seniority = []\n",
    "    job_cat = []\n",
    "    salary = []\n",
    "    requirements = []\n",
    "    post_date = []\n",
    "\n",
    "    for entry in soup.find_all('h1', {'id': \"job_title\"}):\n",
    "        job_title.append(entry.renderContents())\n",
    "\n",
    "    for entry in soup.find_all('p', {'name': \"company\"}):\n",
    "        company.append(entry.renderContents())\n",
    "\n",
    "    for entry in soup.find_all('span', {'class': \"black-60 db f6 fw4 mv1\"}):\n",
    "        job_id.append(entry.renderContents())\n",
    "    \n",
    "    for entry in soup.find_all('p', {'id': \"seniority\"}):\n",
    "        seniority.append(entry.renderContents())\n",
    "\n",
    "    for entry in soup.find_all('p', {'id': \"job-categories\"}):\n",
    "        job_cat.append(entry.renderContents()) \n",
    "\n",
    "    for entry in soup.find_all('span', {'id': \"last_posted_date\"}):\n",
    "        post_date.append(entry.renderContents())     \n",
    "\n",
    "    salary_all = soup.find_all(\"span\", attrs={'class': 'dib'})\n",
    "    list_of_inner_text = [x.text for x in salary_all]\n",
    "    salary_text = '/ '.join(list_of_inner_text)\n",
    "    salary.append(salary_text)\n",
    "\n",
    "    requirement_all = soup.find_all(\"div\", attrs={'id': 'requirements'})\n",
    "    list_of_inner_text = [x.text for x in requirement_all]\n",
    "    requirements_text = ', '.join(list_of_inner_text)\n",
    "    requirements.append(requirements_text)\n",
    "\n",
    "    data = pd.DataFrame(columns = ['Job_Id','Job_Title','Company','Date_Posted','Salary',\n",
    "                                   'Seniority','Category','Requirements'])\n",
    "\n",
    "    data = data.append({'Job_Id':job_id,'Job_Title':job_title,'Company':company,\n",
    "                    'Date_Posted':post_date,'Salary':salary,'Seniority':seniority,\n",
    "                    'Category':job_cat,'Requirements':requirements},ignore_index=True) \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:179: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"/Users/yesplum/desktop/GApro/chromedriver/chromedriver\")\n",
    "driver.get(\"https://www.mycareersfuture.sg/\")\n",
    "elem = driver.find_element_by_name(\"search-text\")\n",
    "elem.send_keys(\"data science\") #job search keyword\n",
    "elem.send_keys(Keys.RETURN)\n",
    "sleep(3)\n",
    "current_url = driver.current_url\n",
    "sleep(3)\n",
    "driver.close()\n",
    "\n",
    "y=0\n",
    "links = []\n",
    "\n",
    "for page in range(3):\n",
    "    \n",
    "    new_next_url = current_url.replace('page=' + str(y),'page=' +str(page))\n",
    "    #print(new_next_url)\n",
    "\n",
    "    driver2 = webdriver.Chrome(executable_path=\"/Users/yesplum/desktop/GApro/chromedriver/chromedriver\")\n",
    "    driver2.get(new_next_url)\n",
    "    sleep(3)\n",
    "    html1 = driver2.page_source \n",
    "    driver2.close()\n",
    "\n",
    "    soup = BeautifulSoup(html1, 'lxml', from_encoding=\"utf-8\")\n",
    "\n",
    "    for entry in soup.find_all(\"a\", attrs={'class': re.compile(r'JobCard')}):\n",
    "        link = entry.get('href')\n",
    "        links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.DataFrame()\n",
    "\n",
    "for i in range (len(links)):\n",
    "    job_url  =  \"https://www.mycareersfuture.sg%s\" % links[i]\n",
    "    temp_df = page_scrap(job_url)\n",
    "    job_df = job_df.append(temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.to_csv('ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
